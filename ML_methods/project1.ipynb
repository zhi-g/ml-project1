{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from proj1_helpers import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../Data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change -999s to median of column (feature) and standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "for col in tX.T:\n",
    "    med = np.median(col[col != -999])\n",
    "    col[col == -999] = med\n",
    "    \n",
    "#keep model index column seperate\n",
    "model_index = tX[:, 22]\n",
    "\n",
    "#remove model index column from tx\n",
    "tX = np.delete(tX, 22, 1)\n",
    "    \n",
    "#Standardize\n",
    "#tX, mean_x, std_x = standardize(tX)\n",
    "tX2 = np.hstack((np.ones((tX.shape[0],1)), tX))\n",
    "\n",
    "print(tX2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Polyonmial Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree = 2\n",
    "#polyX = np.full((tX.shape[0], tX.shape[1] * (degree+1)), 0.0)\n",
    "polyX = list()\n",
    "for row in tX2:\n",
    "    polyX.append(build_poly2(row, degree))\n",
    "\n",
    "PolyXNP = np.array(polyX)\n",
    "PolyXNP2 = PolyXNP.reshape((PolyXNP.shape[0], PolyXNP.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 59)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolyXNP2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with 4 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fused = np.c_[y, PolyXNP2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ml_functions import *\n",
    "\n",
    "#First we build a polynomial model to represent the features\n",
    "#phi = build_poly(tX, 1)\n",
    "\n",
    "Fused_0 = Fused[model_index == 0.0]\n",
    "Fused_1 = Fused[model_index == 1.0]\n",
    "Fused_2 = Fused[model_index == 2.0]\n",
    "Fused_3 = Fused[model_index == 3.0]\n",
    "#TODO remove feature\n",
    "gamma = 0.05\n",
    "lambda_ = 0.5\n",
    "max_iters = 100\n",
    "\n",
    "loss1, w1 = pen_logistic_regression_test(Fused_0[:,0], Fused_0[:,1:Fused_0.shape[1]], lambda_, gamma, max_iters)\n",
    "loss2, w2 = pen_logistic_regression_test(Fused_1[:,0], Fused_1[:,1:Fused_1.shape[1]], lambda_, gamma, max_iters)\n",
    "loss3, w3 = pen_logistic_regression_test(Fused_2[:,0], Fused_2[:,1:Fused_2.shape[1]], lambda_, gamma, max_iters)\n",
    "loss4, w4 = pen_logistic_regression_test(Fused_3[:,0], Fused_3[:,1:Fused_3.shape[1]], lambda_, gamma, max_iters)\n",
    "\n",
    "#weights = ridge_regression(y, tX, 0.01)\n",
    "\n",
    "weights = (w1, w2, w3, w4)\n",
    "\n",
    "#w = logistic_regression(y,tX,gamma,max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights2 = (w1.reshape((w1.shape[0],)), w2.reshape((w2.shape[0],)),w3.reshape((w3.shape[0],)), w4.reshape((w4.shape[0],)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../Data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 59)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in tX_test.T:\n",
    "    med = np.median(col[col != -999])\n",
    "    col[col == -999] = med\n",
    "\n",
    "#keep model index column seperate\n",
    "model_index2 = tX_test[:, 22]\n",
    "\n",
    "#remove model index column from tx\n",
    "tX_test = np.delete(tX_test, 22, 1)\n",
    "\n",
    "#Standardize\n",
    "#tX_test, mean_x, std_x = standardize(tX_test)\n",
    "tX_test2 = np.hstack((np.ones((tX_test.shape[0],1)), tX_test))\n",
    "\n",
    "#Use list to calculate polynomial faster\n",
    "polyXTest = list()\n",
    "for row in tX_test2:\n",
    "    polyXTest.append(build_poly2(row, degree))\n",
    "\n",
    "PolyXNPTest = np.array(polyXTest)\n",
    "PolyXNPTest2 = PolyXNPTest.reshape((PolyXNPTest.shape[0], PolyXNPTest.shape[2]))\n",
    "\n",
    "PolyXNPTest2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "(568238,)\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../Data/resultLogisticPenalized6.csv' \n",
    "# TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels3(weights2, PolyXNPTest2, degree, model_index2)\n",
    "print(y_pred.shape)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. ..., -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
