{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "from ml_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../Data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change -999s to median of column (feature) and standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in tX.T:\n",
    "    med = np.median(col[col != -999])\n",
    "    col[col == -999] = med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove column 22 for use a model index for multiple model case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keep model index column seperate\n",
    "model_index = tX[:, 22]\n",
    "\n",
    "#remove model index column from tx\n",
    "tX2 = np.delete(tX, 22, 1)\n",
    "    \n",
    "print(tX2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Polyonmial Matrix for 4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree = 2\n",
    "#polyX = np.full((tX.shape[0], tX.shape[1] * (degree+1)), 0.0)\n",
    "polyX = list()\n",
    "for row in tX2:\n",
    "    polyX.append(build_poly2(row, degree))\n",
    "\n",
    "PolyXNP = np.array(polyX)\n",
    "PolyXNP2 = PolyXNP.reshape((PolyXNP.shape[0], PolyXNP.shape[2]))\n",
    "\n",
    "#Standardize\n",
    "PolyXNP2 = standardize(PolyXNP2)\n",
    "PolyXNP2 = np.hstack((np.ones((PolyXNP2.shape[0],1)), PolyXNP2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PolyXNP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 31)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX4 = standard2(tX)\n",
    "\n",
    "tXSingleTestOnly = np.hstack((np.ones((tX.shape[0],1)), tX4))\n",
    "tXSingleTestOnly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85667,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma = 0.0000002\n",
    "lambda_ = 0.01\n",
    "max_iters = 10000\n",
    "\n",
    "initial_w = np.zeros((tXSingleTestOnly.shape[1], 1))\n",
    "\n",
    "losses, w = reg_logistic_regression_test(y, tXSingleTestOnly, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52825,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sigmoid(np.dot(tXSingleTestOnly, w))\n",
    "y_pred[y_pred > 0.5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22315644],\n",
       "       [ 0.29686668],\n",
       "       [-0.11854201],\n",
       "       ..., \n",
       "       [ 0.28013609],\n",
       "       [ 0.38984445],\n",
       "       [ 0.23547771]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with 4 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fused = np.c_[y, PolyXNP2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00464148,  0.00520637,  0.0079336 , ...,  0.00267873,\n",
       "        0.0021645 ,  0.00230664])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fused[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 59)\n",
      "(99913,)\n",
      "(59, 1)\n",
      "[-45062.96678364]\n",
      "(77544, 59)\n",
      "(77544,)\n",
      "(59, 1)\n",
      "[-46246.10469503]\n",
      "(50379, 59)\n",
      "(50379,)\n",
      "(59, 1)\n",
      "[-35208.7823107]\n",
      "(22164, 59)\n",
      "(22164,)\n",
      "(59, 1)\n",
      "[-14088.95896855]\n"
     ]
    }
   ],
   "source": [
    "Fused_0 = Fused[model_index == 0.0]\n",
    "Fused_1 = Fused[model_index == 1.0]\n",
    "Fused_2 = Fused[model_index == 2.0]\n",
    "Fused_3 = Fused[model_index == 3.0]\n",
    "\n",
    "gamma = 0.000000005\n",
    "lambda_ = 0.01\n",
    "max_iters = 300\n",
    "\n",
    "loss1, w1 = pen_logistic_regression_test(Fused_0[:,0], Fused_0[:,1:Fused_0.shape[1]], lambda_, gamma, max_iters)\n",
    "loss2, w2 = pen_logistic_regression_test(Fused_1[:,0], Fused_1[:,1:Fused_1.shape[1]], lambda_, gamma, max_iters)\n",
    "loss3, w3 = pen_logistic_regression_test(Fused_2[:,0], Fused_2[:,1:Fused_2.shape[1]], lambda_, gamma, max_iters)\n",
    "loss4, w4 = pen_logistic_regression_test(Fused_3[:,0], Fused_3[:,1:Fused_3.shape[1]], lambda_, gamma, max_iters)\n",
    "\n",
    "#weights = ridge_regression(y, tX, 0.01)\n",
    "\n",
    "weights = (w1, w2, w3, w4)\n",
    "\n",
    "#w = logistic_regression(y,tX,gamma,max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.81000640e-04],\n",
       "       [  1.75434470e-04],\n",
       "       [ -1.00380667e-04],\n",
       "       [ -1.03889103e-03],\n",
       "       [ -1.83943166e-04],\n",
       "       [ -5.46980441e-05],\n",
       "       [ -5.84469312e-05],\n",
       "       [  3.44737414e-04],\n",
       "       [  3.16619405e-05],\n",
       "       [  5.97276403e-03],\n",
       "       [  4.46729048e-03],\n",
       "       [  2.38242374e-03],\n",
       "       [  6.88586941e-04],\n",
       "       [ -2.37516441e-03],\n",
       "       [ -2.22599176e-03],\n",
       "       [ -2.33347898e-04],\n",
       "       [ -5.98702456e-04],\n",
       "       [ -5.63192275e-05],\n",
       "       [ -4.01072574e-07],\n",
       "       [  5.97863361e-04],\n",
       "       [  1.38698720e-04],\n",
       "       [ -5.56188745e-04],\n",
       "       [ -1.13249818e-04],\n",
       "       [  7.55604335e-03],\n",
       "       [  8.33594150e-03],\n",
       "       [  1.06574608e-02],\n",
       "       [  1.04020830e-02],\n",
       "       [  5.30304787e-04],\n",
       "       [  5.10825168e-05],\n",
       "       [  1.45945856e-04],\n",
       "       [ -6.07518500e-04],\n",
       "       [  2.29077758e-04],\n",
       "       [  8.87424315e-05],\n",
       "       [ -1.02566795e-04],\n",
       "       [ -3.06482316e-05],\n",
       "       [  1.63544730e-04],\n",
       "       [ -6.91904229e-04],\n",
       "       [  4.01762389e-04],\n",
       "       [  2.65169196e-04],\n",
       "       [  8.49376015e-05],\n",
       "       [  4.83278047e-06],\n",
       "       [  5.46095271e-04],\n",
       "       [  3.96088694e-04],\n",
       "       [  2.80261010e-04],\n",
       "       [  7.19237444e-05],\n",
       "       [  4.73804354e-04],\n",
       "       [  7.18141769e-05],\n",
       "       [  4.28789903e-04],\n",
       "       [  9.22022549e-04],\n",
       "       [  4.52286745e-04],\n",
       "       [  3.91988736e-04],\n",
       "       [  2.63911625e-04],\n",
       "       [  1.47450076e-05],\n",
       "       [  3.25825954e-04],\n",
       "       [  1.13784753e-03],\n",
       "       [  1.39084005e-04],\n",
       "       [  1.88083935e-05],\n",
       "       [  4.53071217e-04],\n",
       "       [  8.20147699e-05]])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights2 = (w1.reshape((w1.shape[0],)), w2.reshape((w2.shape[0],)),w3.reshape((w3.shape[0],)), w4.reshape((w4.shape[0],)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../Data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Data Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tX_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-47931cbd17be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m999\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m999\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#keep model index column seperate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tX_test' is not defined"
     ]
    }
   ],
   "source": [
    "for col in tX_test.T:\n",
    "    med = np.median(col[col != -999])\n",
    "    col[col == -999] = med\n",
    "\n",
    "#keep model index column seperate\n",
    "model_index2 = tX_test[:, 22]\n",
    "\n",
    "#remove model index column from tx\n",
    "tX_test = np.delete(tX_test, 22, 1)\n",
    "\n",
    "#Use list to calculate polynomial faster\n",
    "polyXTest = list()\n",
    "for row in tX_test:\n",
    "    polyXTest.append(build_poly2(row, degree))\n",
    "\n",
    "PolyXNPTest = np.array(polyXTest)\n",
    "PolyXNPTest2 = PolyXNPTest.reshape((PolyXNPTest.shape[0], PolyXNPTest.shape[2]))\n",
    "\n",
    "#Standardize\n",
    "#tX_test, mean_x, std_x = standardize(tX_test)\n",
    "PolyXNPTest2 = standard2(PolyXNPTest2)\n",
    "PolyXNPTest2 = np.hstack((np.ones((PolyXNPTest2.shape[0],1)), PolyXNPTest2))\n",
    "\n",
    "\n",
    "PolyXNPTest2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55204022  0.52927842  0.55873225 ...,  0.55711393  0.52899992\n",
      "  0.56392765]\n",
      "(568238,)\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../Data/resultLogisticPenalized6.csv' \n",
    "# TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels3(weights2, PolyXNPTest2, degree, model_index2)\n",
    "print(y_pred.shape)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       ..., \n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test data Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 31)\n"
     ]
    }
   ],
   "source": [
    "tX_test_single = tX_test\n",
    "for col in tX_test_single.T:\n",
    "    med = np.median(col[col != -999])\n",
    "    col[col == -999] = med\n",
    "    \n",
    "tX_test_single = standard2(tX_test_single)\n",
    "\n",
    "tX_test_single = np.hstack((np.ones((tX_test_single.shape[0],1)), tX_test_single))\n",
    "\n",
    "print(tX_test_single.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18008755]\n",
      " [ 0.21627501]\n",
      " [ 0.32692703]\n",
      " ..., \n",
      " [ 0.50223199]\n",
      " [ 0.44951093]\n",
      " [ 0.1534008 ]]\n",
      "(568238, 1)\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../Data/resultLogisticPenalizedSingleModel2.csv' \n",
    "# TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels_logistic_single(w, tX_test_single)\n",
    "print(y_pred.shape)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred<0.5]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
